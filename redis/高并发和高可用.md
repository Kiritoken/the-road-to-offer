# 高并发和高可用

redis不能支撑高并发的瓶颈：单机
单机redis能承载的QPS：几万

## 读写分离
+ master Redis
+ salve redis

一主多从，写请求写master，master把数据同步到slave节点，读请求读slave redis
可以加slave redis
单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。

+ 可支持水平扩展

## 过期key处理
slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。

## Redis replication 的核心机制

Redis 采用异步方式复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；
一个 master node 是可以配置多个 slave node 的；
slave node 也可以连接其他的 slave node；
slave node 做复制的时候，不会 block master node 的正常工作；
slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；
slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。

## master持久化对于主从架构的安全保障意义
如果采用了主从架构，那么建议必须开启master node的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。


master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。


# Redis 主从复制的核心原理
+ 初次连接：全量复制
+ 主从复制的断点续传
[https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-master-slave.md](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-master-slave.md)



## 高可用性
一个slave挂了，不影响
master挂了，全部失效

## 哨兵模式


## Cluster集群模式
根据官方推荐，集群部署至少要 3 台以上的master节点，最好使用 3 主 3 从六个节点的模式
类似于es分布式架构

+ 哨兵模式或者主从模式下的问题：
master节点的数据和salve的节点数据是一样的，master最大能容量多少，slave也就只能容纳多大
***redis单master单机内存瓶颈问题***

+ 使用集群模式可以支持横向扩容了，通过横向扩容master节点，

## 特点
+ 支撑N个redis master node 节点，每个master node 都可以挂载多个slave node
+ 也可以保持读写分离，
+ 高可用，每个master节点都有slvae节点，如果某个master节点挂掉，将会自动启动将某个slave切换成master
+ 多master+ 读写分离 + 高可用
+ 主要针对海量数据

## 集群模式的核心数据分布算法
***hash slot算法***


+ hash算法
对master节点数量取模，分布到对应的master节点上去
弊端：
如果有一台master节点宕机了，需要将大量的数据重新计算写入缓存中，新的请求根据2 取模，导致大量请求失效，几乎接近100%


+ 一致性hash算法 + 虚拟节点

任何一个master节点，只会影响之前在这个master节点的数据

受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。

弊端：缓存热点问题
***容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。***
***虚拟节点***

+ hash slot算法
Redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。

Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。

***任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。***
所有数据都是对16384 slot的数量取模

## 集群模式节点间通信

+ gossip 协议
Redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。
+ 坏处：
可能会有延时
ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。
+ 使用10000端口号


## jedis 与redis集群模式的交互

+ 请求重定向 moved 重定向
    + 客户端任意挑选一个redis实例发送命令，每个redis实例收到命令，计算key对应的hashslot
    + 如果slot在本地，则将结果返回
    + 如果slot不在本地，则发送给客户端moved重定向
    + 客户端收到重定向后直接去对应的节点获取数据


+ smart jedis
   基于重定向的客户端，非常消耗IO，因为大部分情况下，可能会出现一次重定向，才能找到正确的节点
   所以大部分的客户端比如jedis 会在本地维护一个hashslot-》node的映射表


+ jedisCluster
    + jedisCLuster初始化的时候会随机挑选一个节点，获取这个节点的元数据，然后初始化hashslot - 》 node的映射表
    + 同时为每个node创建jedispool连接池
    + 每次基于jedisCluster的操作，首先会在本地计算hashslot，获取对应的节点
    + 如果对应的节点返回moved重定向，那么会利用原数据对hashslot - 》 node的映射进行更新
    + 重复上面的步骤，知道找到对应的节点


```java
public class RedisClusterNode extends RedisNode {

	private SlotRange slotRange;
	private @Nullable LinkState linkState;
	private Set<Flag> flags;
```


+ ask重定向
    +  如果hash slot正在迁移，会返回ask重定向，此时并不会更新映射表的缓存
